{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEd6hFbmc1F0urOdswFh85",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qatatsha-curtin/ISYS5002/blob/main/Test_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnGHEJX1snEP",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install hands-on-ai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hands_on_ai import NLP\n",
        "\n",
        "def parse_weather_question(question: str):\n",
        "    # Initialize NLP object\n",
        "    nlp = NLP()\n",
        "\n",
        "    # Process the user's question\n",
        "    parsed_question = nlp.process(question)\n",
        "\n",
        "    # Extract relevant information\n",
        "    location = None\n",
        "    weather_query = None\n",
        "\n",
        "    # Example rules to find a location and weather query (we'll refine this later)\n",
        "    if 'weather' in parsed_question['keywords']:\n",
        "        weather_query = parsed_question['keywords'].get('weather', None)\n",
        "\n",
        "    if parsed_question.get('entities'):\n",
        "        location = parsed_question['entities'].get('location', None)\n",
        "\n",
        "    return location, weather_query\n",
        "\n",
        "# Example usage\n",
        "question = \"What’s the weather in London today?\"\n",
        "location, query = parse_weather_question(question)\n",
        "print(f\"Location: {location}, Query: {query}\")\n"
      ],
      "metadata": {
        "id": "wID571p2KWdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hands_on_ai\n",
        "print(dir(hands_on_ai))\n"
      ],
      "metadata": {
        "id": "Nu8o_1pOKgTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hands_on_ai.chat\n",
        "print(dir(hands_on_ai.chat))\n"
      ],
      "metadata": {
        "id": "FRS0tW5mLJg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hands_on_ai.chat import get_response\n",
        "\n",
        "question = \"What’s the weather like in Tokyo tomorrow?\"\n",
        "response = get_response(question)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "YbZle7YsLUKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hands_on_ai.chat import friendly_bot\n",
        "\n",
        "response = friendly_bot(\"What’s the weather like in Tokyo tomorrow?\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "iCL5cua5LaDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "try:\n",
        "    response = requests.get(\"https://www.google.com\")\n",
        "    print(\"Internet OK:\", response.status_code)\n",
        "except Exception as e:\n",
        "    print(\"Internet Error:\", str(e))\n"
      ],
      "metadata": {
        "id": "t7GLf3PxLp5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question: str):\n",
        "    # Process the question using spaCy\n",
        "    doc = nlp(question)\n",
        "    print (doc.ents)\n",
        "    # Initialize the values for location and query\n",
        "    location = None\n",
        "    weather_query = None\n",
        "\n",
        "    # Extract named entities (like locations)\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == 'GPE':  # GPE = Geopolitical Entity, often locations/countries\n",
        "            location = ent.text\n",
        "\n",
        "    # Check for keywords in the question (weather-related terms)\n",
        "    weather_keywords = ['weather', 'temperature', 'rain', 'forecast', 'sunny', 'humidity']\n",
        "    for token in doc:\n",
        "        if token.text.lower() in weather_keywords:\n",
        "            weather_query = token.text.lower()\n",
        "\n",
        "    return location, weather_query\n",
        "\n",
        "# Example usage\n",
        "question = \"What’s the weather in London today?\"\n",
        "location, query = parse_weather_question(question)\n",
        "print(f\"Location: {location}, Query: {query}\")\n"
      ],
      "metadata": {
        "id": "hqKyi4MzL1CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "question = \"What’s the weather in London today?\"\n",
        "location, query = parse_weather_question(question)\n",
        "print(f\"Location: {location}, Query: {query}\")"
      ],
      "metadata": {
        "id": "JUiwEEF5L5ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the small English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # Extract location using named entity recognition\n",
        "    location = None\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"GPE\":\n",
        "            location = ent.text\n",
        "            break\n",
        "\n",
        "    # Basic weather keyword detection\n",
        "    weather_types = {\n",
        "        'temperature': ['temperature', 'hot', 'cold', 'warm', 'cool'],\n",
        "        'rain': ['rain', 'raining', 'rainfall'],\n",
        "        'forecast': ['forecast', 'weather', 'conditions'],\n",
        "        'snow': ['snow', 'snowing'],\n",
        "        'wind': ['wind', 'windy']\n",
        "    }\n",
        "\n",
        "    detected_type = 'forecast'\n",
        "    for token in doc:\n",
        "        for key, keywords in weather_types.items():\n",
        "            if token.lemma_.lower() in keywords:\n",
        "                detected_type = key\n",
        "                break\n",
        "\n",
        "    return {\n",
        "        'location': location,\n",
        "        'weather_type': detected_type\n",
        "    }\n"
      ],
      "metadata": {
        "id": "uaS8538zNlrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hands-on-ai"
      ],
      "metadata": {
        "id": "ihsRXXRYQybB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hands_on_ai.config import load_config, save_config, get_server_url, get_model\n",
        "\n",
        "# Get configuration values\n",
        "config = load_config()  # Returns dict with all config\n",
        "model = get_model()     # Get default LLM model\n",
        "server = get_server_url()  # Get Ollama server URL\n",
        "\n",
        "# Save configuration\n",
        "config[\"model\"] = \"llama3\"\n",
        "save_config(config)"
      ],
      "metadata": {
        "id": "Lh7KcFtoQ4j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hands_on_ai.chat import get_response, pirate_bot, coder_bot\n",
        "\n",
        "# Basic chat usage\n",
        "response = get_response(\"Tell me about planets\")\n",
        "\n",
        "# Use a personality bot\n",
        "pirate_response = pirate_bot(\"Tell me about sailing ships\")"
      ],
      "metadata": {
        "id": "TcLRWhsFQ9iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List available modules\n",
        "handsonai list\n",
        "\n",
        "# Configure the toolkit\n",
        "handsonai config set model llama3\n",
        "\n",
        "# Check environment and setup\n",
        "handsonai doctor"
      ],
      "metadata": {
        "id": "ddC6LV3yRCs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List available tools\n",
        "agent tools\n",
        "\n",
        "# Ask a question that requires tools\n",
        "agent ask \"Calculate 25 * 4 and convert to binary\"\n",
        "\n",
        "# Interactive agent session\n",
        "agent interactive\n",
        "\n",
        "# Launch agent web interface\n",
        "agent web"
      ],
      "metadata": {
        "id": "druJyA7uRJ_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hands_on_ai.chat import get_response, pirate_bot\n",
        "\n",
        "# Simple chat with default model\n",
        "response = get_response(\"What is the capital of France?\")\n",
        "print(response)  # Paris\n",
        "\n",
        "# Chat with a personality\n",
        "pirate_response = pirate_bot(\"Tell me about sailing ships\")\n",
        "print(pirate_response)  # Arr matey! Sailing ships be magnificent vessels..."
      ],
      "metadata": {
        "id": "tC_uK718RNEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_weather_question(question):\n",
        "    \"\"\"\n",
        "    Parse a user's weather question in plain English.\n",
        "\n",
        "    Args:\n",
        "        question (str): The user's input.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing:\n",
        "            - 'location': The location mentioned by the user (if any)\n",
        "            - 'weather_type': The type of weather info requested (if any)\n",
        "    \"\"\"\n",
        "    # Convert to lowercase to make matching easier\n",
        "    question = question.lower()\n",
        "\n",
        "    # Simple list of keywords for weather types\n",
        "    weather_keywords = ['temperature', 'rain', 'snow', 'forecast', 'wind', 'humidity']\n",
        "\n",
        "    # Find weather type\n",
        "    weather_type = None\n",
        "    for keyword in weather_keywords:\n",
        "        if keyword in question:\n",
        "            weather_type = keyword\n",
        "            break\n",
        "\n",
        "    # Naive way to find location: assume it's the last word in the sentence\n",
        "    words = question.split()\n",
        "    location = words[-1] if len(words) > 1 else None\n",
        "\n",
        "    return {\n",
        "        'location': location,\n",
        "        'weather_type': weather_type\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "question = \"What is the temperature in Paris?\"\n",
        "parsed = parse_weather_question(question)\n",
        "print(parsed)\n"
      ],
      "metadata": {
        "id": "-5LjFYjER6xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    \"\"\"\n",
        "    Parse a user's weather question in plain English.\n",
        "\n",
        "    Args:\n",
        "        question (str): The user's input.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing:\n",
        "            - 'location': The location mentioned by the user (if any)\n",
        "            - 'weather_type': The type of weather info requested (if any)\n",
        "    \"\"\"\n",
        "    # Convert to lowercase to make matching easier\n",
        "    question_lower = question.lower()\n",
        "\n",
        "    # Simple list of keywords for weather types\n",
        "    weather_keywords = ['temperature', 'rain', 'snow', 'forecast', 'wind', 'humidity']\n",
        "\n",
        "    # Find weather type\n",
        "    weather_type = None\n",
        "    for keyword in weather_keywords:\n",
        "        if keyword in question_lower:\n",
        "            weather_type = keyword\n",
        "            break\n",
        "\n",
        "    # Attempt to extract location\n",
        "    location = None\n",
        "    # Look for the word 'in' or 'at' as an indicator\n",
        "    if ' in ' in question_lower:\n",
        "        location_part = question_lower.split(' in ')[1]\n",
        "        # Remove punctuation\n",
        "        location = location_part.translate(str.maketrans('', '', string.punctuation)).title()\n",
        "    elif ' at ' in question_lower:\n",
        "        location_part = question_lower.split(' at ')[1]\n",
        "        location = location_part.translate(str.maketrans('', '', string.punctuation)).title()\n",
        "    else:\n",
        "        # Fallback: last word\n",
        "        words = question_lower.split()\n",
        "        location = words[-1].translate(str.maketrans('', '', string.punctuation)).title()\n",
        "\n",
        "    return {\n",
        "        'location': location,\n",
        "        'weather_type': weather_type\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "questions = [\n",
        "    \"What is the temperature in Paris?\",\n",
        "    \"Will it rain in New York tomorrow?\",\n",
        "    \"Show me the wind forecast at San Francisco.\",\n",
        "    \"Is it snowing in London?\",\n",
        "    \"Paris weather tomorrow\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(parse_weather_question(q))\n"
      ],
      "metadata": {
        "id": "wGb1ObXaSV7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load English NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # Extract location entities (GPE)\n",
        "    location = None\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"GPE\":\n",
        "            location = ent.text\n",
        "            break\n",
        "\n",
        "    # Detect weather type using simple keyword matching for now\n",
        "    weather_keywords = ['temperature', 'rain', 'snow', 'forecast', 'wind', 'humidity', 'weather']\n",
        "    weather_type = None\n",
        "    for token in doc:\n",
        "        if token.lemma_.lower() in weather_keywords:\n",
        "            weather_type = token.lemma_.lower()\n",
        "            break\n",
        "\n",
        "    return {\n",
        "        'location': location,\n",
        "        'weather_type': weather_type\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "questions = [\n",
        "    \"Paris weather tomorrow\",\n",
        "    \"Will it rain in New York today?\",\n",
        "    \"How windy is it in San Francisco?\",\n",
        "    \"Amman forecast\",\n",
        "    \"Perth what's happening there in terms of weather and rain\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(parse_weather_question(q))\n"
      ],
      "metadata": {
        "id": "Q1ry9kUxSWXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import string\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract location using NER\n",
        "    location = None\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"GPE\":\n",
        "            location = ent.text\n",
        "            break\n",
        "\n",
        "    # 2. Fallback: look for capitalized words not at the start of sentence\n",
        "    if not location:\n",
        "        # Split sentence into words\n",
        "        words = question.split()\n",
        "        capitalized_words = [w.strip(string.punctuation) for w in words if w[0].isupper()]\n",
        "        # Remove weather-related words\n",
        "        weather_keywords = ['Weather', 'Rain', 'Snow', 'Forecast', 'Wind', 'Humidity', 'Temperature']\n",
        "        location_candidates = [w for w in capitalized_words if w not in weather_keywords]\n",
        "        if location_candidates:\n",
        "            location = ' '.join(location_candidates)\n",
        "\n",
        "    # 3. Detect weather type using simple keyword matching\n",
        "    weather_keywords_lower = ['temperature', 'rain', 'snow', 'forecast', 'wind', 'humidity', 'weather']\n",
        "    weather_type = None\n",
        "    for token in doc:\n",
        "        if token.lemma_.lower() in weather_keywords_lower:\n",
        "            weather_type = token.lemma_.lower()\n",
        "            break\n",
        "\n",
        "    return {\n",
        "        'location': location,\n",
        "        'weather_type': weather_type\n",
        "    }\n",
        "\n",
        "# Test input\n",
        "question = \"Perth what's happening there in terms of weather and rain\"\n",
        "print(parse_weather_question(question))\n"
      ],
      "metadata": {
        "id": "iDyDnZUtU0w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"Paris weather tomorrow\",\n",
        "    \"Will it rain in New York today?\",\n",
        "    \"How windy is it in San Francisco?\",\n",
        "    \"Amman forecast\",\n",
        "    \"Perth what's happening there in terms of weather and rain\"\n",
        "]\n",
        "for q in questions:\n",
        "    print(parse_weather_question(q))"
      ],
      "metadata": {
        "id": "MwD8hMv0U5AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import string\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract location using NER\n",
        "    location = None\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"GPE\":\n",
        "            location = ent.text\n",
        "            break\n",
        "\n",
        "    # 2. Fallback: look for capitalized words not at the start of sentence\n",
        "    if not location:\n",
        "        words = question.split()\n",
        "        capitalized_words = [w.strip(string.punctuation) for w in words if w[0].isupper()]\n",
        "        weather_keywords = ['Weather', 'Rain', 'Snow', 'Forecast', 'Wind', 'Humidity', 'Temperature']\n",
        "        location_candidates = [w for w in capitalized_words if w not in weather_keywords]\n",
        "        if location_candidates:\n",
        "            location = ' '.join(location_candidates)\n",
        "\n",
        "    # 3. Detect all weather types in the question\n",
        "    weather_keywords_lower = ['temperature', 'rain', 'snow', 'forecast', 'wind', 'humidity', 'weather']\n",
        "    weather_types = []\n",
        "    for token in doc:\n",
        "        if token.lemma_.lower() in weather_keywords_lower:\n",
        "            if token.lemma_.lower() not in weather_types:\n",
        "                weather_types.append(token.lemma_.lower())\n",
        "\n",
        "    return {\n",
        "        'location': location,\n",
        "        'weather_type': weather_types  # return list of all detected types\n",
        "    }\n",
        "\n",
        "# Test input\n",
        "question = \"Perth what's happening there in terms of weather and rain\"\n",
        "print(parse_weather_question(question))\n"
      ],
      "metadata": {
        "id": "Rk_VZ0TIVKk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import string\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract all location entities (GPE)\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "\n",
        "    # 2. Fallback: look for capitalized words not in weather keywords\n",
        "    if not locations:\n",
        "        words = question.split()\n",
        "        capitalized_words = [w.strip(string.punctuation) for w in words if w[0].isupper()]\n",
        "        weather_keywords = ['Weather', 'Rain', 'Snow', 'Forecast', 'Wind', 'Humidity', 'Temperature']\n",
        "        locations = [w for w in capitalized_words if w not in weather_keywords]\n",
        "\n",
        "    # 3. Detect all weather types in the question\n",
        "    weather_keywords_lower = ['temperature', 'rain', 'snow', 'forecast', 'wind', 'humidity', 'weather']\n",
        "    weather_types = []\n",
        "    for token in doc:\n",
        "        if token.lemma_.lower() in weather_keywords_lower:\n",
        "            if token.lemma_.lower() not in weather_types:\n",
        "                weather_types.append(token.lemma_.lower())\n",
        "\n",
        "    return {\n",
        "        'locations': locations if locations else None,\n",
        "        'weather_type': weather_types if weather_types else None\n",
        "    }\n",
        "\n",
        "# Test input\n",
        "questions = [\n",
        "    \"What's the weather and rain like in Perth and Sydney?\",\n",
        "    \"Tell me the temperature in London, Paris, and New York today\",\n",
        "    \"Will it snow in Moscow and Toronto tomorrow?\",\n",
        "    \"perth and sydney weather and also the rain please\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(parse_weather_question(q))\n"
      ],
      "metadata": {
        "id": "KhKL3pDZVhKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import string\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Small example city list for fallback\n",
        "KNOWN_CITIES = ['Perth', 'Sydney', 'London', 'Paris', 'New York', 'Moscow', 'Toronto']\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract GPEs from NER (if capitalized)\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "\n",
        "    # 2. Fallback: detect words before weather keywords as potential locations\n",
        "    if not locations:\n",
        "        weather_keywords_lower = ['temperature', 'rain', 'snow', 'forecast', 'wind', 'humidity', 'weather']\n",
        "        words = question.split()\n",
        "        # Find index of first weather keyword\n",
        "        keyword_index = None\n",
        "        for i, w in enumerate(words):\n",
        "            if w.lower().strip(string.punctuation) in weather_keywords_lower:\n",
        "                keyword_index = i\n",
        "                break\n",
        "        if keyword_index:\n",
        "            # Take all words before first weather keyword\n",
        "            potential_locations = words[:keyword_index]\n",
        "            # Remove common conjunctions/stopwords\n",
        "            stopwords = ['and', 'also', 'the', 'please', 'in', 'at']\n",
        "            potential_locations = [w.strip(string.punctuation).title() for w in potential_locations if w.lower() not in stopwords]\n",
        "            # Keep only known cities\n",
        "            locations = [w for w in potential_locations if w in KNOWN_CITIES]\n",
        "\n",
        "    # 3. Detect all weather types\n",
        "    weather_keywords_lower = ['temperature', 'rain', 'snow', 'forecast', 'wind', 'humidity', 'weather']\n",
        "    weather_types = []\n",
        "    for token in doc:\n",
        "        if token.lemma_.lower() in weather_keywords_lower and token.lemma_.lower() not in weather_types:\n",
        "            weather_types.append(token.lemma_.lower())\n",
        "\n",
        "    return {\n",
        "        'locations': locations if locations else None,\n",
        "        'weather_type': weather_types if weather_types else None\n",
        "    }\n",
        "\n",
        "# Test input\n",
        "question = \"perth and sydney weather and also the rain please\"\n",
        "print(parse_weather_question(question))\n"
      ],
      "metadata": {
        "id": "ySzDHPlnV9CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test input\n",
        "questions = [\n",
        "    \"What's the weather and rain like in Perth and Sydney?\",\n",
        "    \"Tell me the temperature in London, Paris, and New York today\",\n",
        "    \"Will it snow in Moscow and Toronto tomorrow?\",\n",
        "    \"perth and sydney weather and also the rain please\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(parse_weather_question(q))"
      ],
      "metadata": {
        "id": "05t4KJmGWDIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import string\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Lists for time words and weather attributes\n",
        "TIME_KEYWORDS = ['today', 'tomorrow', 'tonight', 'morning', 'evening', 'week', 'weekend', 'now']\n",
        "WEATHER_KEYWORDS = ['temperature', 'rain', 'snow', 'forecast', 'wind', 'humidity', 'weather', 'hot', 'cold', 'storm', 'humid']\n",
        "\n",
        "# Common stopwords to ignore when guessing locations\n",
        "STOPWORDS = ['and', 'also', 'the', 'please', 'in', 'at', 'for', 'me', 'there', 'is', 'it']\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    \"\"\"\n",
        "    Parse a natural language weather question.\n",
        "\n",
        "    Args:\n",
        "        question (str): User's weather-related question\n",
        "\n",
        "    Returns:\n",
        "        dict: Extracted information including locations, time periods, and weather attributes\n",
        "    \"\"\"\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract locations using NER (GPE)\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "\n",
        "    # 2. Fallback: detect potential location words before first weather keyword\n",
        "    if not locations:\n",
        "        words = question.split()\n",
        "        # Find index of first weather keyword\n",
        "        keyword_index = None\n",
        "        for i, w in enumerate(words):\n",
        "            if w.lower().strip(string.punctuation) in WEATHER_KEYWORDS:\n",
        "                keyword_index = i\n",
        "                break\n",
        "        if keyword_index is not None:\n",
        "            potential_locations = words[:keyword_index]\n",
        "            # Remove stopwords and punctuation\n",
        "            potential_locations = [w.strip(string.punctuation).title() for w in potential_locations if w.lower() not in STOPWORDS]\n",
        "            if potential_locations:\n",
        "                locations = potential_locations\n",
        "\n",
        "    # 3. Extract time periods\n",
        "    time_periods = []\n",
        "    words = question.split()\n",
        "    for w in words:\n",
        "        if w.lower().strip(string.punctuation) in TIME_KEYWORDS:\n",
        "            time_periods.append(w.lower())\n",
        "\n",
        "    # 4. Extract weather attributes\n",
        "    weather_attributes = []\n",
        "    for token in doc:\n",
        "        lemma = token.lemma_.lower()\n",
        "        if lemma in WEATHER_KEYWORDS and lemma not in weather_attributes:\n",
        "            weather_attributes.append(lemma)\n",
        "\n",
        "    return {\n",
        "        'locations': locations if locations else None,\n",
        "        'time_periods': time_periods if time_periods else None,\n",
        "        'weather_attributes': weather_attributes if weather_attributes else None\n",
        "    }\n",
        "\n",
        "# Test examples\n",
        "questions = [\n",
        "    \"perth and sydney weather and also the rain please for 3 days\",\n",
        "    \"Will it rain in New York tomorrow?\",\n",
        "    \"How hot is it in Paris today?\",\n",
        "    \"Show me the wind forecast at San Francisco and London this week\",\n",
        "    \"Tokyo temperature and humidity now\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(parse_weather_question(q))\n"
      ],
      "metadata": {
        "id": "QI_ZtVB8Z3Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    \"\"\"\n",
        "    Parse a natural language weather question using NLP only.\n",
        "\n",
        "    Args:\n",
        "        question (str): User's weather-related question\n",
        "\n",
        "    Returns:\n",
        "        dict: Extracted information including locations, time periods, and weather attributes\n",
        "    \"\"\"\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract locations using spaCy GPE entities\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "\n",
        "    # 2. Extract time periods using spaCy DATE or TIME entities\n",
        "    time_periods = [ent.text for ent in doc.ents if ent.label_ in (\"DATE\", \"TIME\")]\n",
        "\n",
        "    # 3. Extract weather-related attributes\n",
        "    # Approach: take nouns/adjectives in the sentence that are not locations or times\n",
        "    weather_attributes = []\n",
        "    for token in doc:\n",
        "        if token.pos_ in (\"NOUN\", \"ADJ\") and token.ent_type_ not in (\"GPE\", \"DATE\", \"TIME\"):\n",
        "            lemma = token.lemma_.lower()\n",
        "            if lemma not in weather_attributes:\n",
        "                weather_attributes.append(lemma)\n",
        "\n",
        "    return {\n",
        "        'locations': locations if locations else None,\n",
        "        'time_periods': time_periods if time_periods else None,\n",
        "        'weather_attributes': weather_attributes if weather_attributes else None\n",
        "    }\n",
        "\n",
        "# Test input\n",
        "questions = [\n",
        "    \"perth and sydney weather and also the rain please for 3 days\",\n",
        "    \"Will it rain in New York tomorrow?\",\n",
        "    \"How hot is it in Paris today?\",\n",
        "    \"Show me the wind forecast at San Francisco and London this week\",\n",
        "    \"Tokyo temperature and humidity now\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(parse_weather_question(q))\n"
      ],
      "metadata": {
        "id": "K1ArvIzyaa5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    \"\"\"\n",
        "    Parse a natural language weather question using only NLP (no hard-coded lists).\n",
        "\n",
        "    Args:\n",
        "        question (str): User's weather-related question\n",
        "\n",
        "    Returns:\n",
        "        dict: Extracted information including locations, time periods, and weather attributes\n",
        "    \"\"\"\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract locations using GPE entities\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "\n",
        "    # 2. Extract time periods using DATE or TIME entities\n",
        "    time_periods = [ent.text for ent in doc.ents if ent.label_ in (\"DATE\", \"TIME\")]\n",
        "\n",
        "    # 3. Extract weather-related attributes\n",
        "    # Take nouns/adjectives that are not part of locations or time periods\n",
        "    weather_attributes = []\n",
        "    for token in doc:\n",
        "        if token.pos_ in (\"NOUN\", \"ADJ\") and token.ent_type_ not in (\"GPE\", \"DATE\", \"TIME\"):\n",
        "            lemma = token.lemma_.lower()\n",
        "            if lemma not in weather_attributes:\n",
        "                weather_attributes.append(lemma)\n",
        "\n",
        "    # 4. Contextual fallback for locations (words before first weather noun/adjective)\n",
        "    if not locations:\n",
        "        for i, token in enumerate(doc):\n",
        "            if token.pos_ in (\"NOUN\", \"ADJ\") and token.ent_type_ not in (\"GPE\", \"DATE\", \"TIME\"):\n",
        "                # All words before this token\n",
        "                candidate_locations = [t.text.title() for t in doc[:i] if t.pos_ in (\"PROPN\", \"NOUN\")]\n",
        "                if candidate_locations:\n",
        "                    locations = candidate_locations\n",
        "                break\n",
        "\n",
        "    return {\n",
        "        'locations': locations if locations else None,\n",
        "        'time_periods': time_periods if time_periods else None,\n",
        "        'weather_attributes': weather_attributes if weather_attributes else None\n",
        "    }\n",
        "\n",
        "# Test examples\n",
        "questions = [\n",
        "    \"perth and sydney weather and also the rain please for 3 days\",\n",
        "    \"Will it rain in New York tomorrow?\",\n",
        "    \"How hot is it in Paris today?\",\n",
        "    \"Show me the wind forecast at San Francisco and London this week\",\n",
        "    \"Tokyo temperature and humidity now\",\n",
        "    \"paris london and rome weather forecast for next week\",\n",
        "    \"how's the rain in sydney vs melbourne tomorrow?\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(parse_weather_question(q))\n"
      ],
      "metadata": {
        "id": "hepunXP5bNY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    \"\"\"\n",
        "    Parse a natural language weather question using only NLP (no hard-coded lists).\n",
        "\n",
        "    Args:\n",
        "        question (str): User's weather-related question\n",
        "\n",
        "    Returns:\n",
        "        dict: Extracted information including locations, time periods, and weather attributes\n",
        "    \"\"\"\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract locations using GPE entities\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "\n",
        "    # 2. Extract time periods using DATE or TIME entities\n",
        "    time_periods = [ent.text for ent in doc.ents if ent.label_ in (\"DATE\", \"TIME\")]\n",
        "\n",
        "    # 3. Contextual fallback for locations (words before first weather noun/adjective)\n",
        "    fallback_locations = []\n",
        "    for i, token in enumerate(doc):\n",
        "        if token.pos_ in (\"NOUN\", \"ADJ\") and token.ent_type_ not in (\"GPE\", \"DATE\", \"TIME\"):\n",
        "            # All proper nouns or nouns before this token\n",
        "            candidate_locations = [t.text.title() for t in doc[:i] if t.pos_ in (\"PROPN\", \"NOUN\")]\n",
        "            if candidate_locations:\n",
        "                fallback_locations = candidate_locations\n",
        "            break\n",
        "    # Only use fallback if NER found nothing\n",
        "    if not locations:\n",
        "        locations = fallback_locations\n",
        "\n",
        "    # 4. Extract weather-related attributes (exclude locations and time periods)\n",
        "    location_set = set([l.lower() for l in locations]) if locations else set()\n",
        "    time_set = set([t.lower() for t in time_periods]) if time_periods else set()\n",
        "\n",
        "    weather_attributes = []\n",
        "    for token in doc:\n",
        "        lemma = token.lemma_.lower()\n",
        "        if token.pos_ in (\"NOUN\", \"ADJ\") and lemma not in location_set and lemma not in time_set:\n",
        "            if lemma not in weather_attributes:\n",
        "                weather_attributes.append(lemma)\n",
        "\n",
        "    return {\n",
        "        'locations': locations if locations else None,\n",
        "        'time_periods': time_periods if time_periods else None,\n",
        "        'weather_attributes': weather_attributes if weather_attributes else None\n",
        "    }\n",
        "\n",
        "# Test input\n",
        "question = \"perth and sydney weather and also the rain please for 3 days\"\n",
        "print(parse_weather_question(question))\n"
      ],
      "metadata": {
        "id": "sx0VCwPubbVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    \"\"\"\n",
        "    Parse a natural language weather question for weather data retrieval.\n",
        "\n",
        "    Args:\n",
        "        question (str): User's weather-related question\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'locations': list of locations (str),\n",
        "            'forecast_days': int (1-5),\n",
        "            'weather_attributes': list of keywords\n",
        "        }\n",
        "    \"\"\"\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract locations using GPE entities\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "\n",
        "    # 2. Contextual fallback for locations (proper nouns/nouns before first weather noun/adjective)\n",
        "    fallback_locations = []\n",
        "    for i, token in enumerate(doc):\n",
        "        if token.pos_ in (\"NOUN\", \"ADJ\") and token.ent_type_ not in (\"GPE\", \"DATE\", \"TIME\"):\n",
        "            candidate_locations = [t.text.title() for t in doc[:i] if t.pos_ in (\"PROPN\", \"NOUN\")]\n",
        "            if candidate_locations:\n",
        "                fallback_locations = candidate_locations\n",
        "            break\n",
        "    if not locations:\n",
        "        locations = fallback_locations\n",
        "\n",
        "    # 3. Extract numeric forecast_days (e.g., \"3 days\")\n",
        "    forecast_days = 5  # default\n",
        "    numeric_days = re.findall(r'\\b(\\d+)\\s+days?\\b', question.lower())\n",
        "    if numeric_days:\n",
        "        forecast_days = min(max(int(numeric_days[0]), 1), 5)  # clamp 1-5\n",
        "\n",
        "    # 4. Extract weather attributes (exclude locations and time entities)\n",
        "    location_set = set([l.lower() for l in locations]) if locations else set()\n",
        "    weather_attributes = []\n",
        "    for token in doc:\n",
        "        lemma = token.lemma_.lower()\n",
        "        if token.pos_ in (\"NOUN\", \"ADJ\") and token.ent_type_ not in (\"GPE\", \"DATE\", \"TIME\") and lemma not in location_set:\n",
        "            if lemma not in weather_attributes:\n",
        "                weather_attributes.append(lemma)\n",
        "\n",
        "    return {\n",
        "        'locations': locations if locations else None,\n",
        "        'forecast_days': forecast_days,\n",
        "        'weather_attributes': weather_attributes if weather_attributes else None\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "questions = [\n",
        "    \"perth and sydney weather and also the rain please for 3 days\",\n",
        "    \"Will it rain in New York tomorrow?\",\n",
        "    \"How hot is it in Paris today?\",\n",
        "    \"Show me the 2 days wind forecast at San Francisco and London this week\",\n",
        "    \"Tokyo temperature and humidity now\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(parse_weather_question(q))\n"
      ],
      "metadata": {
        "id": "cR52RrVJbbvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract locations using GPE entities\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "\n",
        "    # 2. Contextual fallback for locations if NER fails\n",
        "    if not locations:\n",
        "        locations = []\n",
        "        # Collect consecutive proper nouns or nouns at the start until a weather noun/adjective\n",
        "        collecting = True\n",
        "        for token in doc:\n",
        "            if token.pos_ in (\"NOUN\", \"ADJ\") and collecting:\n",
        "                # Stop collecting at first weather noun/adjective\n",
        "                break\n",
        "            if token.pos_ in (\"PROPN\", \"NOUN\"):\n",
        "                locations.append(token.text.title())\n",
        "            elif token.text.lower() in [\"and\", \"vs\", \",\"]:\n",
        "                continue\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    # 3. Extract numeric forecast_days\n",
        "    forecast_days = 5\n",
        "    numeric_days = re.findall(r'\\b(\\d+)\\s+days?\\b', question.lower())\n",
        "    if numeric_days:\n",
        "        forecast_days = min(max(int(numeric_days[0]), 1), 5)\n",
        "\n",
        "    # 4. Extract weather attributes (exclude locations and DATE/TIME entities)\n",
        "    location_set = set([l.lower() for l in locations]) if locations else set()\n",
        "    weather_attributes = []\n",
        "    for token in doc:\n",
        "        lemma = token.lemma_.lower()\n",
        "        if token.pos_ in (\"NOUN\", \"ADJ\") and token.ent_type_ not in (\"GPE\", \"DATE\", \"TIME\") and lemma not in location_set:\n",
        "            if lemma not in weather_attributes:\n",
        "                weather_attributes.append(lemma)\n",
        "\n",
        "    return {\n",
        "        'locations': locations if locations else None,\n",
        "        'forecast_days': forecast_days,\n",
        "        'weather_attributes': weather_attributes if weather_attributes else None\n",
        "    }\n",
        "\n",
        "# Test input\n",
        "question = \"perth and sydney weather and also the rain please for 3 days\"\n",
        "print(parse_weather_question(question))\n"
      ],
      "metadata": {
        "id": "7YlKu_-3cLdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract locations using spaCy GPE entities\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "\n",
        "    # 2. Contextual fallback for lowercase/informal locations if NER fails\n",
        "    if not locations:\n",
        "        locations = []\n",
        "        skip_tokens = {\"and\", \"vs\", \",\"}\n",
        "        collecting = True\n",
        "        for token in doc:\n",
        "            text_lower = token.text.lower()\n",
        "            if text_lower in skip_tokens:\n",
        "                continue\n",
        "            if token.pos_ in (\"PROPN\", \"NOUN\"):\n",
        "                locations.append(token.text.title())\n",
        "            elif token.pos_ in (\"NOUN\", \"ADJ\"):\n",
        "                # Stop collecting at the first noun/adjective likely to be weather-related\n",
        "                break\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    # 3. Extract numeric forecast_days (e.g., \"3 days\")\n",
        "    forecast_days = 5\n",
        "    numeric_days = re.findall(r'\\b(\\d+)\\s+days?\\b', question.lower())\n",
        "    if numeric_days:\n",
        "        forecast_days = min(max(int(numeric_days[0]), 1), 5)\n",
        "\n",
        "    # 4. Extract weather attributes (exclude locations and DATE/TIME entities)\n",
        "    location_set = set([l.lower() for l in locations]) if locations else set()\n",
        "    weather_attributes = []\n",
        "    for token in doc:\n",
        "        lemma = token.lemma_.lower()\n",
        "        if token.pos_ in (\"NOUN\", \"ADJ\") and token.ent_type_ not in (\"GPE\", \"DATE\", \"TIME\") and lemma not in location_set:\n",
        "            if lemma not in weather_attributes:\n",
        "                weather_attributes.append(lemma)\n",
        "\n",
        "    return {\n",
        "        'locations': locations if locations else None,\n",
        "        'forecast_days': forecast_days,\n",
        "        'weather_attributes': weather_attributes if weather_attributes else None\n",
        "    }\n",
        "\n",
        "# Test input\n",
        "question = \"perth and sydney weather and also the rain please for 3 days\"\n",
        "print(parse_weather_question(question))\n"
      ],
      "metadata": {
        "id": "JNiQuTrccSlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    \"\"\"\n",
        "    Parse a natural language weather question to extract locations and forecast duration.\n",
        "\n",
        "    Args:\n",
        "        question (str): User's weather-related question\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'locations': list of location strings,\n",
        "            'forecast_days': int (1-5)\n",
        "        }\n",
        "    \"\"\"\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract locations using spaCy GPE entities\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "\n",
        "    # 2. Contextual fallback for lowercase/informal locations if NER fails\n",
        "    if not locations:\n",
        "        locations = []\n",
        "        skip_tokens = {\"and\", \"vs\", \",\"}\n",
        "        for token in doc:\n",
        "            text_lower = token.text.lower()\n",
        "            if text_lower in skip_tokens:\n",
        "                continue\n",
        "            if token.pos_ in (\"PROPN\", \"NOUN\"):\n",
        "                locations.append(token.text.title())\n",
        "            elif token.pos_ in (\"NOUN\", \"ADJ\"):\n",
        "                # Stop collecting at the first noun/adjective likely unrelated to location\n",
        "                break\n",
        "\n",
        "    # 3. Extract numeric forecast_days (e.g., \"3 days\"), default 5\n",
        "    forecast_days = 5\n",
        "    numeric_days = re.findall(r'\\b(\\d+)\\s+days?\\b', question.lower())\n",
        "    if numeric_days:\n",
        "        forecast_days = min(max(int(numeric_days[0]), 1), 5)\n",
        "\n",
        "    return {\n",
        "        'locations': locations if locations else None,\n",
        "        'forecast_days': forecast_days\n",
        "    }\n",
        "\n",
        "# Test example\n",
        "question = \"perth and sydney weather and also the rain please for 3 days\"\n",
        "print(parse_weather_question(question))\n"
      ],
      "metadata": {
        "id": "4pfkXQoEcfmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def get_weather_data(location, forecast_days=5):\n",
        "    \"\"\"\n",
        "    Retrieve weather data for a specified location from wttr.in.\n",
        "\n",
        "    Args:\n",
        "        location (str): City or location name\n",
        "        forecast_days (int): Number of days to forecast (1-5)\n",
        "\n",
        "    Returns:\n",
        "        dict: Weather data including current conditions and forecast\n",
        "    \"\"\"\n",
        "    # Ensure forecast_days is between 1 and 5\n",
        "    forecast_days = min(max(forecast_days, 1), 5)\n",
        "\n",
        "    # Build wttr.in URL for JSON output\n",
        "    url = f\"https://wttr.in/{location}?format=j1\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise error if request fails\n",
        "        data = response.json()\n",
        "\n",
        "        # Extract current condition\n",
        "        current_condition = data.get(\"current_condition\", [{}])[0]\n",
        "\n",
        "        # Extract forecast for specified days\n",
        "        forecast = data.get(\"weather\", [])[:forecast_days]\n",
        "\n",
        "        # Build simplified result\n",
        "        result = {\n",
        "            \"location\": location,\n",
        "            \"current\": current_condition,\n",
        "            \"forecast\": forecast\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error retrieving weather data: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "location = \"Sydney\"\n",
        "forecast_days = 3\n",
        "weather = get_weather_data(location, forecast_days)\n",
        "print(weather)\n"
      ],
      "metadata": {
        "id": "AC7lDwvwdQaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "import requests\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# -----------------------------\n",
        "# NLP-based parser\n",
        "# -----------------------------\n",
        "def parse_weather_question(question):\n",
        "    \"\"\"\n",
        "    Parse a natural language weather question to extract locations and forecast duration.\n",
        "\n",
        "    Args:\n",
        "        question (str): User's weather-related question\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'locations': list of location strings,\n",
        "            'forecast_days': int (1-5)\n",
        "        }\n",
        "    \"\"\"\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract locations using spaCy GPE entities\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "\n",
        "    # 2. Contextual fallback for lowercase/informal locations if NER fails\n",
        "    if not locations:\n",
        "        locations = []\n",
        "        skip_tokens = {\"and\", \"vs\", \",\"}\n",
        "        for token in doc:\n",
        "            text_lower = token.text.lower()\n",
        "            if text_lower in skip_tokens:\n",
        "                continue\n",
        "            if token.pos_ in (\"PROPN\", \"NOUN\"):\n",
        "                locations.append(token.text.title())\n",
        "            elif token.pos_ in (\"NOUN\", \"ADJ\"):\n",
        "                # Stop collecting at the first noun/adjective likely unrelated to location\n",
        "                break\n",
        "\n",
        "    # 3. Extract numeric forecast_days (e.g., \"3 days\"), default 5\n",
        "    forecast_days = 5\n",
        "    numeric_days = re.findall(r'\\b(\\d+)\\s+days?\\b', question.lower())\n",
        "    if numeric_days:\n",
        "        forecast_days = min(max(int(numeric_days[0]), 1), 5)\n",
        "\n",
        "    return {\n",
        "        'locations': locations if locations else None,\n",
        "        'forecast_days': forecast_days\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# Weather data retrieval\n",
        "# -----------------------------\n",
        "def get_weather_data(location, forecast_days=5):\n",
        "    \"\"\"\n",
        "    Retrieve weather data for a specified location from wttr.in.\n",
        "\n",
        "    Args:\n",
        "        location (str): City or location name\n",
        "        forecast_days (int): Number of days to forecast (1-5)\n",
        "\n",
        "    Returns:\n",
        "        dict: Weather data including current conditions and forecast\n",
        "    \"\"\"\n",
        "    forecast_days = min(max(forecast_days, 1), 5)\n",
        "    url = f\"https://wttr.in/{location}?format=j1\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        current_condition = data.get(\"current_condition\", [{}])[0]\n",
        "        forecast = data.get(\"weather\", [])[:forecast_days]\n",
        "\n",
        "        return {\n",
        "            \"location\": location,\n",
        "            \"current\": current_condition,\n",
        "            \"forecast\": forecast\n",
        "        }\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error retrieving weather data for {location}: {e}\")\n",
        "        return None\n",
        "\n",
        "# -----------------------------\n",
        "# Combined workflow\n",
        "# -----------------------------\n",
        "def fetch_weather_from_question(question):\n",
        "    \"\"\"\n",
        "    Parse question and fetch weather for all locations.\n",
        "    \"\"\"\n",
        "    parsed = parse_weather_question(question)\n",
        "    locations = parsed['locations']\n",
        "    forecast_days = parsed['forecast_days']\n",
        "\n",
        "    if not locations:\n",
        "        print(\"No locations found in your input.\")\n",
        "        return\n",
        "\n",
        "    results = {}\n",
        "    for loc in locations:\n",
        "        weather = get_weather_data(loc, forecast_days)\n",
        "        if weather:\n",
        "            results[loc] = weather\n",
        "\n",
        "    return results\n",
        "\n",
        "# -----------------------------\n",
        "# Example usage\n",
        "# -----------------------------\n",
        "question = \"perth and sydney weather and also the rain please for 3 days\"\n",
        "weather_data = fetch_weather_from_question(question)\n",
        "\n",
        "for loc, data in weather_data.items():\n",
        "    print(f\"\\nWeather for {loc}:\")\n",
        "    print(f\"Current: {data['current']}\")\n",
        "    print(\"Forecast:\")\n",
        "    for day in data['forecast']:\n",
        "        print(day)\n"
      ],
      "metadata": {
        "id": "_OmbsBYYfmR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_weather_question(question):\n",
        "    \"\"\"\n",
        "    Extract only locations and number of forecast days from a natural language question.\n",
        "\n",
        "    Args:\n",
        "        question (str): User input\n",
        "\n",
        "    Returns:\n",
        "        dict: {'locations': [...], 'forecast_days': int}\n",
        "    \"\"\"\n",
        "    doc = nlp(question)\n",
        "\n",
        "    # 1. Extract locations using GPE entities\n",
        "    locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "\n",
        "    # 2. Contextual fallback: collect consecutive proper nouns at the start if NER fails\n",
        "    if not locations:\n",
        "        locations = []\n",
        "        skip_tokens = {\"and\", \"vs\", \",\"}\n",
        "        for token in doc:\n",
        "            text_lower = token.text.lower()\n",
        "            if text_lower in skip_tokens:\n",
        "                continue\n",
        "            if token.pos_ == \"PROPN\":\n",
        "                locations.append(token.text.title())\n",
        "            else:\n",
        "                break  # Stop at first token that is not a proper noun or skip word\n",
        "\n",
        "    # 3. Extract numeric forecast_days (e.g., \"3 days\")\n",
        "    forecast_days = 5  # default\n",
        "    numeric_days = re.findall(r'\\b(\\d+)\\s+days?\\b', question.lower())\n",
        "    if numeric_days:\n",
        "        forecast_days = min(max(int(numeric_days[0]), 1), 5)\n",
        "\n",
        "    return {\n",
        "        'locations': locations if locations else None,\n",
        "        'forecast_days': forecast_days\n",
        "    }\n",
        "\n",
        "# Test input\n",
        "question = \"perth and sydney weather and also the rain please for 3 days\"\n",
        "parsed = parse_weather_question(question)\n",
        "locations = parsed['locations']\n",
        "forecast_days = parsed['forecast_days']\n",
        "print(parse_weather_question(question))\n"
      ],
      "metadata": {
        "id": "6xH2_7hXgA5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def get_weather_data(location, forecast_days=5):\n",
        "    \"\"\"\n",
        "    Retrieve weather data for a specified location from wttr.in.\n",
        "\n",
        "    Args:\n",
        "        location (str): City or location name\n",
        "        forecast_days (int): Number of days to forecast (1-5)\n",
        "\n",
        "    Returns:\n",
        "        dict: Weather data including current conditions and forecast\n",
        "    \"\"\"\n",
        "    # Ensure forecast_days is between 1 and 5\n",
        "    forecast_days = min(max(forecast_days, 1), 5)\n",
        "\n",
        "    # Build wttr.in URL for JSON output\n",
        "    url = f\"https://wttr.in/{location}?format=j1\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise error if request fails\n",
        "        data = response.json()\n",
        "\n",
        "        # Extract current condition\n",
        "        current_condition = data.get(\"current_condition\", [{}])[0]\n",
        "\n",
        "        # Extract forecast for specified days\n",
        "        forecast = data.get(\"weather\", [])[:forecast_days]\n",
        "\n",
        "        # Build simplified result\n",
        "        result = {\n",
        "            \"location\": location,\n",
        "            \"current\": current_condition,\n",
        "            \"forecast\": forecast\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error retrieving weather data: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "# location = \"Sydney\"\n",
        "# forecast_days = 3\n",
        "weather = get_weather_data(location, forecast_days)\n",
        "print(weather)\n"
      ],
      "metadata": {
        "id": "iku-J0JTgKIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example function for fetching weather data\n",
        "def get_weather_data(location, forecast_days=5):\n",
        "    import requests\n",
        "    forecast_days = min(max(forecast_days, 1), 5)\n",
        "    url = f\"https://wttr.in/{location}?format=j1\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        current_condition = data.get(\"current_condition\", [{}])[0]\n",
        "        forecast = data.get(\"weather\", [])[:forecast_days]\n",
        "        return {\"location\": location, \"current\": current_condition, \"forecast\": forecast}\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error retrieving weather data for {location}: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "PoXWq3INg_ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not locations:\n",
        "    print(\"No locations found in your input.\")\n",
        "else:\n",
        "    for city in locations:\n",
        "        weather = get_weather_data(city, forecast_days)\n",
        "        if weather:\n",
        "            print(f\"\\nWeather for {city}:\")\n",
        "            print(\"Current conditions:\", weather['current'])\n",
        "            print(\"Forecast:\")\n",
        "            for day in weather['forecast']:\n",
        "                print(day)\n"
      ],
      "metadata": {
        "id": "QuX6tYJih7Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parse_weather_question(input())"
      ],
      "metadata": {
        "id": "11PaX1q4qg3B",
        "outputId": "ee1958b4-b5fc-4638-a03c-f5362eed7a49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i want the paly of your amman for the past 3 days \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'locations': None, 'forecast_days': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    }
  ]
}